{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "    def __init__(self,visualization=True):\n",
    "        self.visualization = visualization\n",
    "    \n",
    "    def fit(self,data):\n",
    "        #train with data\n",
    "        self.data = data\n",
    "        # { |\\w\\|:{w,b}}\n",
    "        opt_dict = {}\n",
    "        \n",
    "        transforms = [[1,1],[-1,1],[-1,-1],[1,-1]]\n",
    "        \n",
    "        all_data = np.array([])\n",
    "        for yi in self.data:\n",
    "            all_data = np.append(all_data,self.data[yi])\n",
    "        \n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "        \n",
    "        #with smaller steps our margins and db will be more precise\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      #point of expense\n",
    "                      self.max_feature_value * 0.001,]\n",
    "        \n",
    "        #extremly expensise\n",
    "        b_range_multiple = 5\n",
    "        #we dont need to take as small step as w\n",
    "        b_multiple = 5\n",
    "        \n",
    "        latest_optimum = self.max_feature_value*10\n",
    "        \n",
    "        \"\"\"\n",
    "        objective is to satisfy yi(x.w)+b>=1 for all training dataset such that ||w|| is minimum\n",
    "        for this we will start with random w, and try to satisfy it with making b bigger and bigger\n",
    "        \"\"\"\n",
    "        #making step smaller and smaller to get precise value\n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optimum,latest_optimum])\n",
    "            \n",
    "            #we can do this because convex\n",
    "            optimized = False\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*self.max_feature_value*b_range_multiple,\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        \n",
    "                        #weakest link in SVM fundamentally\n",
    "                        #SMO attempts to fix this a bit\n",
    "                        # ti(xi.w+b) >=1\n",
    "                        for i in self.data:\n",
    "                            for xi in self.data[i]:\n",
    "                                yi=i\n",
    "                                if not yi*(np.dot(w_t,xi)+b)>=1:\n",
    "                                    found_option=False\n",
    "                        if found_option:\n",
    "                            \"\"\"\n",
    "                            all points in dataset satisfy y(w.x)+b>=1 for this cuurent w_t, b\n",
    "                            then put w,b in dict with ||w|| as key #min ||w|| == min ||w||^2\n",
    "                            \"\"\"\n",
    "                            opt_dict[np.linalg.norm(w_t)]=[w_t,b]\n",
    "                \n",
    "                #after w[0] or w[1]<0 then values of w starts repeating itself because of transformation\n",
    "                #Think about it, it is easy\n",
    "                #print(w,len(opt_dict)) Try printing to understand\n",
    "                if w[0]<0:\n",
    "                    optimized=True\n",
    "                    print(\"optimized a step\")\n",
    "                else:\n",
    "                    w = w-step\n",
    "                    \n",
    "            # sorting ||w|| to put the smallest ||w|| at poition 0 \n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #optimal values of w,b\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            \n",
    "            self.w=opt_choice[0]\n",
    "            self.b=opt_choice[1]\n",
    "            #start with new latest_optimum (initial values for w)\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "    \n",
    "    def predict(self,features):\n",
    "        #sign(x.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        if classification!=0 and self.visualization:\n",
    "            self.ax.scatter(features[0],features[1],s=200,marker='*',c=self.colors[classification])\n",
    "        return (classification, np.dot(np.array(features),self.w)+self.b)\n",
    "    \n",
    "    def visualize(self):\n",
    "        \n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "            \n",
    "        [[self.ax.scatter(x[0],x[1],s=100,c=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "        \n",
    "        # hyperplane = x.w+b (actually its a line)\n",
    "        # v = x0.w0+x1.w1+b -> x1 = (v-w[0].x[0]-b)/w1\n",
    "        #psv = 1     psv line ->  x.w+b = 1a small value of b we will increase it later\n",
    "        #nsv = -1    nsv line ->  x.w+b = -1\n",
    "        # dec = 0    db line  ->  x.w+b = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            #returns a x2 value on line when given x1\n",
    "            return (-w[0]*x-b+v)/w[1]\n",
    "       \n",
    "        hyp_x_min= self.min_feature_value*0.9\n",
    "        hyp_x_max = self.max_feature_value*1.1\n",
    "        \n",
    "        # (w.x+b)=1\n",
    "        # positive support vector hyperplane\n",
    "        pav1 = hyperplane(hyp_x_min,self.w,self.b,1)\n",
    "        pav2 = hyperplane(hyp_x_max,self.w,self.b,1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[pav1,pav2],'k')\n",
    "        \n",
    "        # (w.x+b)=-1\n",
    "        # negative support vector hyperplane\n",
    "        nav1 = hyperplane(hyp_x_min,self.w,self.b,-1)\n",
    "        nav2 = hyperplane(hyp_x_max,self.w,self.b,-1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nav1,nav2],'k')\n",
    "        \n",
    "        # (w.x+b)=0\n",
    "        # db support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min,self.w,self.b,0)\n",
    "        db2 = hyperplane(hyp_x_max,self.w,self.b,0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2],'y--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a basic data\n",
    "data_dict = {-1:np.array([[1,7],[2,8],[3,8]]),1:np.array([[5,1],[6,-1],[7,3]])}\n",
    "svm = SVM() # Linear Kernel\n",
    "svm.fit(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.visualize()\n",
    "svm.predict([6,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.visualize()\n",
    "svm.predict([3,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.visualize()\n",
    "svm.predict([4,-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-rebound",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
